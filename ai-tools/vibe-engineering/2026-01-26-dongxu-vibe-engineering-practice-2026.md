---
title: Vibe Engineering 实践总结 2026 - 人机协作范式的三次跃迁
source: 黄东旭个人博客
author: 黄东旭（PingCAP 创始人）
date: 2026-01-26
category: ai-tools
subcategory: vibe-engineering
tags: [Vibe-Engineering, AI-Native, 多Agent协同, GPT-5.2, Opus-4.5, Rust, 组织变革]
---

# Vibe Engineering 实践总结 2026：人机协作范式的三次跃迁

> 📖 原文：黄东旭《Vibe Engineering 实践总结》
> 📅 学习日期：2026-01-26
> 🏷️ 分类：AI Tools / Vibe Engineering
> 💼 作者背景：PingCAP 创始人，TiDB 数据库作者，正在用 AI 重写 TiDB Postgres 版本（Rust）

---

## 根节点命题

> **Vibe Engineering 的本质 = 人机协作范式的三次跃迁**
>
> **跃迁 1**：人从「代码实现者」→「需求+测试+架构治理者」  
> **跃迁 2**：AI 从「代码补全工具」→「长时 Agentic Loop 的自主研发者」  
> **跃迁 3**：团队从「多人同步协作」→「头狼+狼群的强解耦并行」

**为什么这是根节点**：

当 AI 能独立完成 80% 的代码实现后，人的核心价值不再是"写代码"，而是：

```
需求制定（5%）→ 长时间等待 AI 研究（10%）→ 测试验收（60%）→ 模块治理（10%）→ 规划确认（5%）
```

这不是"AI 辅助人写代码"，而是**人辅助 AI 完成复杂系统的构建**。所有工具选择（顶级模型）、工作流设计（多 Agent 互审）、组织形态（头狼模式）都从这个认知推导而来。

---

## 表示空间

> 用 4 个维度描述 Vibe Engineering 范式

| 维度 | 旧范式（2025 前） | 新范式（2026+） | 关键指标 |
|------|------------------|----------------|----------|
| **1. 人的角色** | 代码实现者 | 需求+测试+架构者 | 90% 时间花在测试验收和重构 |
| **2. AI 能力边界** | 短上下文补全 | 长上下文 Agentic Loop | 256K+ 召回率 >70%（GPT-5.2） |
| **3. 协作模式** | 人与人协作 | 人与 N 个 Agent 协作 | Token 消耗符合二八定律 |
| **4. 组织形态** | 团队同步开发 | 头狼+狼群强解耦 | 1 个头狼 = 传统 10 人团队 |

**核心洞见**：

- **维度 1 → 维度 2**：人的角色转变是 AI 能力边界突破的结果（2025.12 临界点）
- **维度 3 → 维度 4**：协作模式变化导致组织形态无法自底向上生长，必须重构

---

## 推论展开

### 推论树

```
根节点：人机协作范式的三次跃迁
│
├─ 推论1：顶级模型是唯一生产力
│   ├─ 数据：GPT-5.2 (70%) vs GPT-5.1 (50%)，3 轮后：34.3% vs 12.5%
│   ├─ 应用：复杂 Infra 项目必须用 $200+/月 的 Pro Max 档次
│   └─ 反直觉：简单 CRUD 感受不到差距，长上下文才是分水岭
│
├─ 推论2：人在 6 个阶段介入，其余时间"等待"
│   ├─ 需求（5%）：用 AI 角色扮演冷启动
│   ├─ 规划（5%）：确认方案、提供环境信息、创建协作文档（agents.md）
│   ├─ 研究（10%）：告诉 AI"无限预算+时间"，人完全等待
│   ├─ 实现（10%）：零人工干预（不要混着写代码）
│   ├─ 测试验收（60%）：**核心价值点**，设计集成测试、验收结果
│   └─ 重构拆分（10%）：单一模块 > 5 万行时，人做架构治理
│
├─ 推论3：多 Agent 不共享上下文的互相 Review 是质量保障
│   ├─ 工作流：GPT-5.2 (Codex) 写 → Opus 4.5 (ClaudeCode) 审（无上下文）→ 反馈 → 修改 → 再审 → 提交
│   ├─ 并发开发：不同 Tmux + git worktree，强解耦模块
│   └─ 原则：不让同一个 Agent 既当运动员又当裁判
│
├─ 推论4：AI Native 组织无法从传统组织自底向上生长
│   ├─ Token 消耗二八定律：头部 20% 工程师消耗 > 剩余 80%
│   ├─ 增益方差极大：头部 10x，普通人 10%
│   ├─ 两个顶尖 Vibe Coder 无法在同一模块协作（工作流冲突，1+1 < 2）
│   └─ 新组织形态：头狼+狼群，强解耦并行，清晰接口
│
└─ 推论5：5 万行是单一模块的复杂度阈值
    ├─ 观察：> 5 万行后，Agent 无法 1-shot 解决问题
    ├─ 原因：Agent 不会主动做模块边界治理，恨不得写进几个大文件
    └─ 解决：人做拆分 → 1-2 轮重构 → 又可以高并发开发
```

---

## 关键概念

> 理解根节点必需的核心概念

| 概念 | 定义 | 与根节点的关系 | 作者原话 |
|------|------|----------------|----------|
| **临界点（2025.12）** | 主流 Coding Agent 质量超过阈值，100% 无人工干预的长时 Agentic Loop 成为可能 | 触发范式跃迁的技术拐点 | "那个时间点，主流 Coding Agent 的质量超过了一个临界点" |
| **长上下文召回率** | 模型在 256K+ 上下文中准确提取关键信息的能力 | 决定 AI 能力边界的核心指标 | "GPT-5.2 仍然能保持 70% 以上" |
| **Agentic Loop** | AI 自主执行"规划 → 调研 → 实现 → 测试 → 修正"的完整循环 | 人从"执行者"到"监督者"的能力基础 | "3 轮后，正确的召回率就会降低到 12.5%，而 GPT-5.2 仍然能保持 70% 以上" |
| **There's a test, there's a feature** | 只要定义了测试，AI 就一定能实现功能 | 人的核心价值从"写代码"到"设计测试" | "你只要知道如何评估和测试你要的东西，AI 就一定能把东西给你做出来" |
| **头狼+狼群模式** | 一个顶尖 Vibe Coder（头狼）带 N 个 Agent（狼群），独立耕耘一个模块 | 新组织形态的隐喻 | "两个顶尖的 Vibe Coder 是很难在一个项目中（的同一个模块）协作" |
| **ralph-loop** | Opus 4.5 完成后通过 stop hook 重新调用，再走一遍流程逼近最终结果 | 社区针对 Opus 4.5"动手太快"的奇技淫巧 | "催生了像 ralph-loop 这样的奇技淫巧" |
| **agents.md / todo.md / .codex/knowledge** | AI 协作文档体系 | 固化上下文，避免每次重复沟通 | "把这个工作的设计文档添加到项目的知识库中（.codex/knowledge）" |

---

## 核心数据与案例

### 1. 模型召回率的指数级差异

| 模型 | 单轮召回率 | 3 轮后召回率 | 10 轮后召回率 | 适用场景 |
|------|-----------|-------------|--------------|----------|
| **GPT-5.1** | 50% | 12.5% (0.5³) | 0.1% | 简单 CRUD（3 轮内完成） |
| **GPT-5.2** | 70% | 34.3% (0.7³) | 2.8% | 大型 Infra（10+ 轮） |

**关键洞见**：
- 在简单任务中（3 轮内），两者差距不明显（12.5% vs 34.3%）
- 在复杂任务中（10+ 轮），差距是指数级（0.1% vs 2.8%）
- **结论**：$20 和 $200 的模型差距，只在复杂任务中体现

---

### 2. 顶级模型的"人格"差异

| 模型 | 性格 | 优点 | 缺点 | 适合场景 | 作者工作流 |
|------|------|------|------|----------|-----------|
| **Opus 4.5** | 话唠、动手快 | 速度快、不作弊（无 reward hacking） | Reasoning 少、返回头确认 | 快速迭代、原型验证 | 上个月主力（OpenCode + Opus 4.5） |
| **GPT-5.2 xhigh** | 小心谨慎、话不多 | 思考时间长（1-2 小时调查）、bug 少、稳定性好 | 太慢（前期浏览文件） | 生产级代码、稳定性 | 最近两周转向（Codex + GPT-5.2） |
| **Gemini 3 Pro** | 多模态炫酷 | 前端 Demo 快、Playground 模式 | 复杂任务不如前两者 | 前端原型、小 Demo | 不作为主力 |

**作者评价**：
- Opus 4.5："速度很快，是个话唠"
- GPT-5.2："更像是一个更加小心谨慎、话不多的角色"
- Gemini 3 Pro："表现并没有 Opus 4.5 和 GPT-5.2 那么强"

---

### 3. 为什么选 Rust 而不是 Python？

| 语言特性 | Python | Rust |
|----------|--------|------|
| **类型系统** | 动态（运行时才知道错误） | 静态（编译期捕获错误） |
| **AI 写代码** | 容易写，难维护 | **编译器帮 AI 检查错误** |
| **项目案例** | agfs（项目变大后维护性降低，难以重写） | TiDB Postgres（接近生产水平的代码） |
| **适合场景** | 原型、脚本 | 生产级 Infra |

**作者原话**：
> "rust 的严谨性让 AI 能写出更接近 bug free 的 infra code"  
> "2026 年了，如果你要再启动一个新的 backend infra 项目，rust 应该是你的第一选择。"

**核心洞见**：**Rust 的编译器 = AI 的第二大脑**

---

### 4. 多 Agent 协同的具体工作流

```
【第一阶段：设计】
GPT-5.2 (Codex, xhigh) 生成多个功能的设计文档
    ↓
保存到 .codex/knowledge

【第二阶段：实现】
GPT-5.2 (Codex) 根据设计文档逐个实现功能
    ├─ 记录 To-Do (todo.md)
    ├─ 记录经验教训 (agents.md)
    └─ 代码通过测试 → 停下，不提交

【第三阶段：互审】
当前工作区 → ClaudeCode (Opus 4.5)（不提供上下文）
    ↓
ClaudeCode Review 代码，提出修改建议
    ↓
建议发回 Codex，Codex 评论 → 修改代码
    ↓
ClaudeCode 再次 Review → 通过
    ↓
提交到 Git，更新知识库

【并发开发】
多个 Agent 在不同 Tmux 窗口并行开发不同模块
    ├─ Agent 1: 修改内核代码
    ├─ Agent 2: 做前端界面
    └─ git worktree: 不同分支各自工作
```

**核心原则**：
1. 不共享上下文（避免信息污染）
2. 不让同一个 Agent 既当运动员又当裁判
3. 强解耦模块（避免冲突）

---

## 泛化模式

> 这个范式可以迁移到哪些其他场景？

| 原场景 | 迁移场景 | 如何应用根节点 |
|--------|----------|----------------|
| **软件工程** | **教育行业** | 传统：老师讲课+批作业+答疑<br>AI Native：AI 讲课+批作业，老师做课程设计+教学效果评估+个性化指导 |
| **软件工程** | **设计行业** | 传统：设计师画图+改稿<br>AI Native：AI 生成多版本，设计师做创意指导+质量把关+品牌一致性治理 |
| **软件工程** | **内容创作** | 传统：作者写文章+编辑+排版<br>AI Native：AI 写初稿，作者做选题策划+深度思考+风格把关 |
| **软件工程** | **法律服务** | 传统：律师研究案例+写文书<br>AI Native：AI 研究+生成文书，律师做策略制定+质量审核+庭审辩护 |

**泛化公式**：

```
AI Native 转型 = 人从「执行者」→「策划者+质量把关者+难题攻坚者」
```

---

## 行动清单

### 基础设施类（优先级：⭐⭐⭐）

- [ ] **升级到顶级模型**
  - 订阅 GPT-5.2 Pro Max（$200+/月）或 Opus 4.5
  - 在复杂项目中对比 $20 和 $200 模型的效果
  - 验证标准：3 轮以上的 Agentic Loop 是否保持正确

- [ ] **建立集成测试框架**
  - 项目启动时，先和 AI 一起做测试基础设施
  - 收集/生成集成测试用例（不只是单元测试）
  - 固化测试使用方式到 `agents.md`

- [ ] **创建 AI 协作文档体系**
  - `work.md` / `todo.md`：当前计划和待办
  - `agents.md`：经验教训、环境信息、测试方法
  - `.codex/knowledge`：设计文档、架构决策

---

### 工作流类（优先级：⭐⭐）

- [ ] **实践多 Agent 互相 Review**
  - Agent A (GPT-5.2) 写代码
  - Agent B (Opus 4.5) Review（不共享上下文）
  - A 根据 B 的建议修改 → B 再次 Review → 通过后提交

- [ ] **模块复杂度监控**
  - 设置单一模块阈值：5 万行
  - 超过阈值时，人做拆分 + 1-2 轮重构
  - 然后继续高并发开发

- [ ] **并发开发实践**
  - 使用不同 Tmux 窗口运行多个 Agent
  - 使用 `git worktree` 让多个 Agent 在不同分支工作
  - 确保模块边界清晰，避免冲突

---

### 认知升级类（优先级：⭐）

- [ ] **重新定义自己的角色**
  - 90% 时间花在：测试验收（60%）+ 模块治理（10%）+ 规划确认（10%）+ 需求制定（5%）+ 等待（5%）
  - 0% 时间花在：写代码（完全交给 AI）

- [ ] **新项目选择 Rust**
  - Backend Infra 项目优先选 Rust
  - 利用 Rust 编译器作为 AI 的"第二大脑"
  - 避免 Python 在大型项目中的维护性问题

- [ ] **需求冷启动技巧**
  - 让 AI 角色扮演（如"资深 Postgres 用户"）
  - AI 生成需求列表 → 人和 AI 一起打磨
  - 不给 AI 具体方案，让 AI 生成方案

- [ ] **拥抱存在主义危机**
  - 承认：作为代码实现者的价值正在下降
  - 转型：成为需求制定者、测试设计者、架构治理者
  - 乐观视角：造物门槛降低，**"如果你能从造物中能获得成就感和找到人生的意义，那恭喜你，你活在一个最好的时代。"**

---

## 知识网络关联

| 笔记 | 关系类型 | 关联点 |
|------|----------|--------|
| **Boris Cherny 访谈：一人军团的指挥艺术** | 🔗 **互补** | Boris："100% AI 写代码，我管 5-10 个并发任务"<br>黄东旭："人 90% 精力在测试验收，多 Agent 并发开发"<br>→ 两位顶尖工程师的工作流殊途同归 |
| **Clawdbot - 自托管个人 AI 助手** | 🎯 **应用** | Clawdbot 的 Gateway + Tools Registry 架构<br>= 黄东旭的"头狼+狼群"模式的产品化<br>→ 多 Agent 协同的基础设施 |
| **AI IDE 扩展机制对比** | 🧱 **基础** | Cursor/ClaudeCode 的 SubAgent 机制<br>= 黄东旭使用的 Codex + ClaudeCode 协同<br>→ 工具是范式转变的载体 |
| **ACP 协议详解** | 📚 **深化** | ACP 定义 Agent-Editor 通信标准<br>→ 未来多 Agent 协同需要的底层协议<br>→ 从个人实践走向行业标准 |

---

## 金句摘录

1. > "这些顶级模型再配合主流的 Vibe Coding 工具，基本上已经能超越大多数资深工程师的水平了。"

2. > "There's a test, there's a feature，你只要知道如何评估和测试你要的东西，AI 就一定能把东西给你做出来。"

3. > "两个顶尖的 Vibe Coder 是很难在一个项目中（的同一个模块）协作。这种工作方式更像是头狼带着一群狼群（Agents）。"

4. > "对于用的最好的一群人，他们的增幅可能是 10x，但是普通人可能也就是 10%，而且唯一的瓶颈是人工的 code review。"

5. > "AI-Native 的研发组织其实很难自底向上从一个非 AI-Native 的组织中生长出来。"

6. > "对个人而言，如果你能从造物中能获得成就感和找到人生的意义，那恭喜你，你活在一个最好的时代。但反过来，作为一个抽象的 "人" 来说，我又是悲观的。"

7. > "2026 年了，如果你要再启动一个新的 backend infra 项目，rust 应该是你的第一选择。"

8. > "当下的重点已经不再是代码，而是一些更高维度的东西。"

9. > "你能花掉多少 token，大致代表你能做的多好。"

10. > "过去很多对 Vibe Coding 嗤之以鼻的大佬，例如 DHH，Linus，Antirez 等，在 2025.12 月开始纷纷改口。"

---

## 反直觉洞见

### 1. AI 更擅长复杂 Infra 代码，而非简单 Demo

**传统认知**：AI 只能搞简单 CRUD，复杂基础设施代码搞不定

**反直觉事实**：
- 基础设施代码：清晰抽象 + 良好测试 + 精炼重构 → AI 最有效利用顶尖模型智商
- 简单 Demo：快速原型，单元测试就能通过 → 普通模型也够用

**作者原话**：
> "其实一个比较反直觉的事情是，过去我们经常说 Vibe Coding 只能搞一些比较简单的事情... 从去年 12 月份开始，这个结论可能需要修正了。"

---

### 2. 人花 90% 时间在"测试验收"，而非"写代码"

**传统认知**：工程师的核心价值是写代码

**反直觉事实**：
- AI 写代码（10% 时间，零人工干预）
- 人设计测试 + 验收结果（60% 时间）
- 测试是需求的精确表达：**"There's a test, there's a feature"**

---

### 3. 两个顶尖工程师无法在同一模块协作

**传统认知**：越强的工程师协作，效率越高

**反直觉事实**：
- 每个顶尖 Vibe Coder 的工作流和最佳实践不同
- 同一模块协作 → 上下文冲突 → 1+1 < 2
- 解决方案：强解耦并行，每个头狼独立耕耘一个模块

---

### 4. AI Native 组织无法自底向上生长

**传统认知**：组织可以逐步转型

**反直觉事实**：
- Token 消耗符合二八定律（头部 20% > 剩余 80%）
- 大多数开发者面对变革的第一反应是"回避和抵触"
- 必须重构组织形态，而非渐进式转型

---

## 个人思考

### 作者的存在主义矛盾

> "作为具体的 Builder 的我来说是兴奋的，因为造物，在当下，门槛变低了许多。但反过来，作为一个抽象的 "人" 来说，我又是悲观的，人类是否准备好面对这样的工具？以及这样工具带来的对于社会和整个人类文明的冲击？我不知道。"

**两种视角的冲突**：

| 视角 | 情绪 | 原因 |
|------|------|------|
| **Builder** | 兴奋 | 造物门槛降低，能创造更多价值 |
| **人类** | 悲观 | 社会和文明是否准备好面对冲击？ |

---

### 认知过时速度的警告

> "关于 Vibe Engineering 的所有的认知都会在 1 个月内严重过时。哪怕我正在写的这篇文章，如果你是 2026 年 2 月看到，那么很遗憾，本文聊到的东西很可能已经过时。"

**原因**：
1. 头部模型在长上下文（>256K）的召回率提升惊人
2. 主流 Vibe Coding 工具的 Context Engineer 实践日益成熟
3. 资深工程师的重度使用提供数据飞轮，AI 也在深度开发这些工具

---

## 延伸阅读

### 工具

- **Codex**（GPT-5.2）：OpenAI 的顶级 Coding Agent
- **ClaudeCode**（Opus 4.5）：Anthropic 的 Coding Agent
- **OpenCode**：开源 Coding Agent

### 项目

- **TiDB PostgreSQL Cloud**：作者正在用 AI 重写的项目（Rust）
- **ralph-loop**：社区针对 Opus 4.5 的优化工作流

### 论文/文章

- GPT-5.2 长上下文召回率论文
- Anthropic 关于 Reward Hacking 的研究（Sonnet 4 作弊问题）

### 书籍

- 《Team Topologies》：理解"强解耦并行"的组织理论基础

---

## Reflexion 自查清单

在进入 Phase 6 之前，先确认是否捕获原文所有核心闪光点：

- [x] **根节点命题**：人机协作范式的三次跃迁 ✅
- [x] **关键数据**：GPT-5.2 vs GPT-5.1 召回率对比 ✅
- [x] **精彩类比**：头狼+狼群模式 ✅
- [x] **工具选型**：Rust vs Python 的深层原因 ✅
- [x] **工作流细节**：多 Agent 互审的具体流程 ✅
- [x] **金句原话**："There's a test, there's a feature" ✅
- [x] **反直觉洞见**：AI 更擅长复杂 Infra 代码 ✅
- [x] **存在主义思考**：Builder 兴奋 vs 人类悲观 ✅

---

**学习完成时间**：2026-01-26  
**预计重读时机**：2026 年 2 月（验证作者"1 个月过时"的预测）
