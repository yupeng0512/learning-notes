# 多 Agent 协作是营销骗局，Eval 大多是自嗨，痛苦才是护城河

> 来源：Lenny's Podcast - Aishwarya Naresh Reganti (ex-OpenAI/Google/Amazon) & Kiriti Badam (OpenAI Kodex)
> 原文：[Why most AI products fail: Lessons from 50+ AI deployments at OpenAI, Google & Amazon](https://www.youtube.com/watch?v=z7T1pCxgvlA)
> 日期：2026-01-25
> 标签：#AIProduct #Agent #Evaluation #ProductManagement #IndustryInsight

## 根节点命题

**AI 产品成功的关键不在技术多牛，而在于「自主权是 AI 赢来的，不是给的」**——你给 AI 越多决策权，就越要确信它「配得上」这份信任。

---

## 核心认知拆解

### 一、AI 产品的两大本质差异

| 维度 | 传统软件 | AI 产品 |
|------|---------|---------|
| **确定性** | 输入→确定输出 | 输入不确定 + 输出不确定 + 过程不确定 |
| **控制权** | 开发者完全掌控 | Agency–Control Tradeoff |

**非确定性的三重叠加**：
```
用户意图 → 无数种自然语言表达方式（输入端不确定）
    ↓
LLM 黑箱处理（过程不确定）
    ↓
对 prompt 措辞极度敏感（输出端不确定）
    ↓
最终要在确定性系统中产生确定性结果
```

**Agency–Control Tradeoff 核心公式**：
```
自主权 ↑ = 控制权 ↓ = 风险 ↑

关键洞察：自主权不是「给」的，是 AI「赢」回来的
```

---

### 二、渐进式自主权演进（最重要的方法论）

**核心原则**：如果你试图在第一天就让 AI 实现全自动化，离项目流产就不远了。

#### 三阶段演进模型（以客服为例）

| 阶段 | 自主性 | 控制性 | 功能 | 收获 |
|------|--------|--------|------|------|
| **V1 路由** | 低 | 高 | 工单分类+分配 | 暴露数据问题、建立分类体系 |
| **V2 辅助** | 中 | 中 | 生成草稿供人审核 | 免费获得错误分析数据 |
| **V3 端到端** | 高 | 低 | 直接解决问题 | 需要前两阶段的信心积累 |

**演进判断标准**：
```
是否可以进入下一阶段？
    ↓
每一两天校准一次，是否还有新的数据分布模式？
    ↓
用户行为是否保持稳定？
    ↓
获得的新信息是否有限？
    ↓
如果以上都是 Yes → 可以进入下一阶段
```

**警告场景**：
- 模型切换（如 GPT-4o → GPT-5）→ 需要重新校准
- 用户行为演变（用户发现系统好用后会提出更复杂需求）→ 需要重新校准

---

### 三、评估（Eval）的真相

#### 评估被误解的三种形态

| 声称 | 实际含义 | 问题 |
|------|----------|------|
| "专家在写评估" | 数据标注/错误分析 | ≠ 构建 LLM Judge |
| "PM 写评估" | 记录预期行为 | ≠ 可上线的反馈闭环 |
| "我们在做评估" | 看榜单选模型 | 根本不是评估 |

#### 评估 vs 生产监控的正确关系

```
评估：把对产品的理解编码进数据集
    ↓
"哪些行为绝对不能做？哪些失败不可接受？"
    ↓
用于部署前验证

生产监控：捕捉未知的失败模式
    ↓
显性信号（点赞/点踩）+ 隐性信号（重新生成 = 不满意）
    ↓
用于部署后发现新问题
```

**关键结论**：评估和生产监控各自捕捉不同类型问题，任何一种都无法覆盖全部风险。

---

### 四、多 Agent 协作的乌托邦骗局

**被误解的幻想**：
```
复杂问题 → 拆解给不同 Agent → 对等协议自主协作 → Agent 乌托邦
```

**现实**：
- 当前开发方式和模型能力不支持对等协作
- 无法控制哪个 Agent 会回复用户
- 需要在各环节设置防护措施，难度极大

**可行的模式**：
| 模式 | 可行性 |
|------|--------|
| 监督 Agent + 执行子 Agent | ✅ 成功 |
| 人类协调员 + 多 Agent | ✅ 成功 |
| 一个大 Agent 统筹所有工作 | ✅ 成功 |
| Agent 通过对等协议自主通信 | ❌ 营销话术 |

---

### 五、痛苦是新的护城河

**核心洞察**：技术门槛在降低，但「折腾的痛苦」在升值。

```
学习 → 实践 → 试错 → 再尝试
    ↓
在数据屎山里反复校准
    ↓
在非确定性陷阱里反复试错
    ↓
积累出的「直觉」= 友商抄不走的钻石
```

**护城河的本质**：
- 不是先发优势
- 不是花哨功能
- 而是从痛苦中提炼的经验——可能是一套评估体系，也可能是某个定制化功能

---

### 六、持续校准与持续开发框架（CC/CD）

#### 框架全景

```
┌─────────────────────────────────────────────────────────┐
│                    持续开发（右侧）                      │
│  明确功能范围 → 整理数据集 → 搭建应用 → 设计评估指标     │
│                         ↓                               │
│                      部署产品                            │
│                         ↓                               │
│                    持续校准（左侧）                      │
│  发现新行为模式 → 分析错误 → 修复问题 → 设计新指标       │
│                         ↓                               │
│                    回到持续开发                          │
└─────────────────────────────────────────────────────────┘
```

#### 为什么需要这个框架？

**反面教训**：
- 端到端 Agent 项目因紧急修复过多不得不停止
- 加拿大航空 Agent 虚构退款政策，公司被迫法律赔偿

**框架价值**：
1. 降低风险：在完全自主前充分了解交互模式
2. 构建隐性日志系统：评估指标只能捕捉已知错误，新模式只有部署后才能发现
3. 避免「大量错误集中爆发」的困境

---

### 七、成功构建 AI 产品的三角形

| 维度 | 关键点 |
|------|--------|
| **领导力** | CEO 必须重建直觉体系，假设自己是会议室里最不懂 AI 的人 |
| **文化** | 赋能型文化（AI 放大你 10 倍）而非威胁型文化（不学 AI 就淘汰） |
| **技术能力** | 深刻理解工作流，知道哪里用 AI、哪里必须有人 |

**领导力的具体实践**（Rackspace CEO）：
```
每天 4:00-6:00 标注为 "Catch up with AI"
    ↓
不安排会议，专门听 AI 播客、看研究进展
    ↓
周末组织白板讨论
    ↓
渗透到公司后续决策中
```

---

### 八、2026 年 AI 产品趋势预测

| 趋势 | 描述 |
|------|------|
| **Proactive Agent** | 不再等候指令，主动预判。上班前修复 5 个 Bug 发到邮箱 |
| **多模态体验** | 人类是多模态生物，语言只是进化后期产物 |
| **编程 Agent** | 仍被低估，非湾区公司使用率很低 |

---

### 九、被低估 vs 被高估

| 被低估 | 被高估/误解 |
|--------|-------------|
| 专注问题本身和产品设计 | 盲目追逐工具、沉迷学习新工具 |
| 编程 Agent（非湾区渗透率低） | 多 Agent 对等协作 |
| 80% 时间应该深入理解工作流 | 构建最复杂最酷炫的模型 |

---

### 十、AI 时代的核心技能

**技能一：判断力与审美**
```
产品实现成本 → 极低
    ↓
竞争核心 → 设计、判断力、审美、独特视角
    ↓
与资历深浅无关
```

**技能二：能动性与主人翁意识**
```
新员工自己开发任务跟踪应用 → 全团队切换使用
    ↓
敢于尝试、乐于重构体验
    ↓
「忙碌却无价值」的时代即将结束
```

**技能三：毅力（痛苦即护城河）**
```
获取信息的渠道 → 极其便捷
    ↓
但构建 AI 产品 → 需要经历学习、实践、试错的痛苦
    ↓
从痛苦中沉淀的能力 = 真正的决胜关键
```

---

## 金句提炼

| 金句 | 含义 |
|------|------|
| "自主权不是给的，是 AI 自己赢回来的" | Agency 需要通过表现来证明 |
| "非确定性是 AI 的魅力，也是它的诅咒" | 在流动界面上构建确定性结果 |
| "痛苦是新的护城河" | 折腾出来的直觉抄不走 |
| "评估很重要，但只靠评估解决所有问题站不住脚" | 评估 + 生产监控缺一不可 |
| "一键 Agent 是营销话术" | 4-6 个月才能产生可观 ROI |
| "80% 时间应该深入理解工作流" | 而非构建最酷炫的模型 |
| "混日子的末日来了" | AI 是照妖镜，低效行为瞬间透明 |

---

## 可迁移方法论

### 1. 限制自主性的多种方式

| 方式 | 示例 |
|------|------|
| 按操作步骤限制 | V1 只能路由，V2 只能建议，V3 才能执行 |
| 按主题/领域限制 | 低风险领域自主，高风险领域必须人工 |
| 按风险等级限制 | 血检 MRI 可自动，侵入性手术必须人工 |

### 2. 信息来源筛选原则

```
信息环境混乱，人人皆有观点
    ↓
选择 2-3 个可信赖的固定来源
    ↓
带着问题与专家交流
    ↓
思考会渗透到后续决策中
```

### 3. 数据集构建的正确姿势

```
不是：跑几个 Benchmark 走过场
    ↓
而是：把 PM 的判断力编码进数据集
    ↓
"哪些行为绝对不能做？哪些失败不可接受？"
```

---

## 反模式警示

| 反模式 | 问题 | 正确做法 |
|--------|------|----------|
| 第一天就全自动化 | 复杂度失控、项目流产 | 从最小版本迭代 |
| 把聊天界面贴到数据上就叫 AI 产品 | 没有重构工作流 | 先拆解再重建 |
| 只做评估或只做监控 | 无法覆盖全部风险 | 两者结合 |
| 追逐一键 Agent | 4-6 个月才能见效 | 构建能学习的飞轮 |
| 威胁型文化推 AI | 领域专家不愿参与 | 赋能型文化 |

---

## 学习收获自评

- [ ] 理解了 AI 产品的两大本质差异（非确定性 + Agency–Control Tradeoff）
- [ ] 掌握了渐进式自主权演进的三阶段模型
- [ ] 明白了评估和生产监控的正确关系
- [ ] 识别了多 Agent 协作的乌托邦骗局
- [ ] 认同「痛苦是新的护城河」的核心洞察
- [ ] 理解了持续校准与持续开发框架的价值
