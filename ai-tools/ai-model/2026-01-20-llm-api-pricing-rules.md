# 大模型 API 计费规则深度解析

> **学习日期**: 2026-01-20
> **来源**: OpenAI、DeepSeek、阿里云、火山引擎、Moonshot 官方文档综合
> **类型**: 技术原理 + 商业逻辑分析

## 一句话总结

大模型计费的本质是「GPU 利用率的货币化映射」——输入并行高效所以便宜，输出串行低效所以贵，缓存复用计算所以打折。

## 根节点命题

> **大模型 API 计费 = 算力成本的直接映射**
> 
> 即：**价格 ∝ GPU 时间 × 计算效率的倒数**

所有定价策略都可从此推导：
- 输出比输入贵 → 因为输出时 GPU 利用率低（串行 vs 并行）
- 缓存命中便宜 → 因为跳过了计算，只有存储成本
- 批处理优惠 → 因为错峰调度提高了整体 GPU 利用率
- 长上下文加价 → 因为注意力计算是 O(n²) 复杂度

## Token 基础

### 什么是 Token？
- Token 是大模型处理文本的最小单位
- 1 Token ≈ 0.75 个英文单词 ≈ 0.5-1 个汉字
- 可以是一个词、数字、标点符号或子词片段
- 例如：`fantastic` → `fan` + `tas` + `tic`（3个token）

### 计费公式
```
费用 = (输入 Token × 输入单价) + (输出 Token × 输出单价)
```

## 各厂商定价对比（每百万 Token）

| 厂商/模型 | 输入价格 | 输出价格 | 缓存命中输入 | 特点 |
|-----------|----------|----------|--------------|------|
| **OpenAI GPT-4o** | $2.5 (~¥18) | $10 (~¥72) | - | 行业标杆 |
| **DeepSeek-V3.2** | ¥2 | ¥3 | ¥0.2（90%折扣） | 极致性价比 |
| **通义千问 qwen-max** | ¥2.4 | ¥9.6 | 支持缓存优惠 | 阶梯计费 |
| **通义千问 qwen-flash** | ¥0.15 | ¥1.5 | 支持 | 极速低价 |
| **通义千问 qwen-turbo** | ¥0.3 | ¥0.6 | - | 超低成本 |
| **豆包 pro-32k** | ¥0.8 | - | - | 价格屠夫(行业低99%) |
| **Kimi kimi-latest-8k** | ¥2 | ¥10 | ¥1 | 长上下文 |

## 推论树

```
根节点：价格 ∝ GPU 时间 × (1 / 计算效率)
│
├─ 推论1：输出比输入贵 3-5 倍
│   ├─ 原因：Decode 阶段是串行的，GPU 利用率仅 10-30%
│   └─ 应用：控制输出长度是省钱的关键杠杆
│
├─ 推论2：缓存命中可省 90%
│   ├─ 原因：存储成本 << 计算成本（约 1:10）
│   └─ 应用：System Prompt 等固定内容应最大化复用
│
├─ 推论3：批处理/异步可省 50%
│   ├─ 原因：厂商可错峰调度，提高整体 GPU 利用率
│   └─ 应用：非实时场景用 Batch API
│
└─ 推论4：长上下文会阶梯加价
    ├─ 原因：Attention 计算复杂度 O(n²)
    └─ 应用：上下文管理比堆长度更重要
```

## 三个核心设计模式

### 模式 1：输入/输出差异定价

```
输入阶段 (Prefill)              输出阶段 (Decode)
┌─────────────────────┐        ┌─────────────────────┐
│ "请解释量子计算"    │        │ "量""子""计""算"... │
│       ↓             │        │       ↓             │
│ [并行处理所有Token] │        │ [逐个生成Token]     │
│       ↓             │        │       ↓             │
│ GPU利用率: 70-90%   │        │ GPU利用率: 10-30%   │
│       ↓             │        │       ↓             │
│ 单价: ¥2/百万Token  │        │ 单价: ¥8/百万Token  │
└─────────────────────┘        └─────────────────────┘
```

**技术原因：自回归解码（Auto-Regressive Decoding）**
- 输入处理（Prefill 阶段）：一次性并行处理所有输入 Token，GPU 计算能力充分利用
- 输出生成（Decode 阶段）：逐个 Token 串行生成，每生成一个都要完整推理一遍，内存带宽瓶颈导致 GPU 利用率低

### 模式 2：上下文缓存机制

```
请求1: [System Prompt] + [用户问题A]
       └── 计算并缓存 ──→ [KV Cache 存储]

请求2: [System Prompt] + [用户问题B]
       └── 命中缓存 ──→ 跳过 System Prompt 计算
                        只计算 [用户问题B] → 省 90%
```

**原理**：
- 将重复使用的内容（如系统提示词、固定文档）缓存起来
- 下次请求时直接读取，无需重新计算
- DeepSeek 使用「硬盘缓存」技术，得益于 MLA 结构大幅压缩 KV Cache

**为什么缓存便宜 90%？**
- 不需要 GPU 计算前向传播
- 只需要从存储（内存/硬盘）读取
- 存储成本远低于计算成本

### 模式 3：批处理优惠

```
实时请求：随机到达 → GPU 忙闲不均 → 全价
批处理：  打包提交 → 厂商错峰调度 → GPU 利用率最大化 → 半价
```

## 特殊计费模式

### Batch 批处理
- 非实时任务，24小时内返回
- 输入/输出均享 50% 折扣

### 阶梯计费（通义千问）
```
0-32K：基础价
32K-128K：2倍
128K-256K：4倍
```

### 思考模式 vs 非思考模式
- 思考模式（如 DeepSeek-R1、Qwen-Plus 思考）输出价格更高
- 因为需要生成思维链（CoT），输出 token 更多

### 多模态计费
- 图片：按张数计费（如通义万相 0.2元/张）
- 视频：按秒计费（如 0.6元/秒）
- 语音：按字符/秒数计费

## 泛化模式

| 原场景 | 迁移场景 | 核心洞察 |
|--------|----------|----------|
| Token 计费 | 云计算资源定价 | 按实际消耗计费比按实例数更合理 |
| 输出比输入贵 | 咨询服务定价 | 「调研」可并行便宜，「定制方案」需串行贵 |
| 缓存机制 | CDN/边缘计算 | 重复内容靠近用户缓存 → 减少回源计算 |
| 批处理优惠 | 航空收益管理 | 灵活时间换低价（红眼航班） |

> **可迁移洞察**：定价的本质 = 成本结构的外化。理解背后的成本结构，就能找到优化空间。

## 行动清单

| 杠杆点 | 具体行动 | 预期收益 | 难度 |
|--------|----------|----------|------|
| **控制输出** | Prompt 中明确限制：「用 3 句话回答」 | 省 30-50% | ⭐ |
| **最大化缓存** | System Prompt 固定在最前面且保持不变 | 省 60-90% | ⭐ |
| **批处理** | 非实时场景（日报、数据标注）用 Batch API | 省 50% | ⭐⭐ |
| **模型分层** | 简单任务用便宜模型，复杂任务再用贵模型 | 省 70-80% | ⭐⭐ |
| **上下文压缩** | 定期总结对话历史，避免上下文膨胀 | 省 40-60% | ⭐⭐⭐ |

**省钱优先级**：`缓存复用 > 控制输出 > 模型分层 > 批处理 > 上下文压缩`

## 金句

> **"输出是串行的，所以输出贵；缓存是存储的，所以缓存便宜；批处理是可调度的，所以批处理打折。"**

## 为什么按 Token 而非调用次数收费？

**核心原因**：Token 数量直接对应 GPU 计算量，而调用次数不对应。
- 一次调用可能处理 10 个 Token，也可能处理 100,000 个 Token
- 如果按次收费，用户会把尽可能多的内容塞进一次调用 → 厂商亏损
- 按 Token 收费 = 按「实际消耗的算力」收费 → 公平且可持续

**类比**：这就像电费按度数收，而不是按「开关次数」收。

## 参考来源

- [OpenAI - What are tokens](https://help.openai.com/zh-hans-cn/articles/4936856-what-are-tokens-and-how-to-count-them)
- [阿里云 - 模型定价](https://help.aliyun.com/zh/model-studio/model-pricing)
- [火山引擎 - 计费说明](https://www.volcengine.com/docs/6492/1544808)
- [DeepSeek - 定价](https://api-docs.deepseek.com/zh-cn/quick_start/pricing)
- [Moonshot - 定价](https://platform.moonshot.cn/docs/pricing/chat)
