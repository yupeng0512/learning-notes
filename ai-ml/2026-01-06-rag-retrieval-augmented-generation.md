# RAG（检索增强生成）精读笔记

> 学习时间：2026-01-06
> 来源：Datawhale all-in-rag 项目
> 在线阅读：https://datawhalechina.github.io/all-in-rag/

---

## 📖 快速概览

| 项目 | 内容 |
|------|------|
| **名称** | RAG（Retrieval-Augmented Generation，检索增强生成） |
| **类型** | 技术范式 / 系统架构 |
| **核心理念** | 让 LLM 学会"开卷考试"——结合内部知识与外部资料 |
| **学习资源** | Datawhale all-in-rag（2.8k ⭐） |
| **技术栈** | Python + LangChain/LlamaIndex + Milvus/ChromaDB + DeepSeek |
| **阅读价值** | ⭐⭐⭐⭐⭐ LLM 应用开发的核心技能，企业落地必备 |

> 💡 **一句话总结**：RAG = **检索（找资料）+ 生成（写答案）**。它让 LLM 从"闭卷考试"变成"开卷考试"，既能用自己学到的知识，也能随时查阅外部资料，从而解决幻觉、知识过时、领域知识缺失等问题。

---

## 🗺️ 知识地图

### RAG 架构全景

```
┌─────────────────────────────────────────────────────────────┐
│                    RAG 双阶段架构                            │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  用户提问                                                    │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ "DeepSeek 的最新版本有什么特性？"                     │   │
│  └─────────────────────────────────────────────────────┘   │
│                          ↓                                  │
│  ═══════════════════════════════════════════════════════   │
│  阶段一：检索（Retrieval）                                  │
│  ═══════════════════════════════════════════════════════   │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ 1. 问题向量化：Embedding Model 将问题转为向量         │   │
│  │ 2. 相似度搜索：在向量数据库中找最相关的文档片段       │   │
│  │ 3. 返回 Top-K 结果                                   │   │
│  └─────────────────────────────────────────────────────┘   │
│                          ↓                                  │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ 检索结果：                                           │   │
│  │ [文档1] DeepSeek-V3 发布于 2024 年 12 月...          │   │
│  │ [文档2] 新增 MoE 架构，671B 参数...                  │   │
│  │ [文档3] 支持 128K 上下文窗口...                      │   │
│  └─────────────────────────────────────────────────────┘   │
│                          ↓                                  │
│  ═══════════════════════════════════════════════════════   │
│  阶段二：生成（Generation）                                 │
│  ═══════════════════════════════════════════════════════   │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ Prompt = 系统指令 + 检索结果 + 用户问题               │   │
│  │                                                      │   │
│  │ "根据以下参考资料回答问题，如果资料中没有答案，      │   │
│  │  请说'我不知道'。                                    │   │
│  │  参考资料：[文档1][文档2][文档3]                     │   │
│  │  问题：DeepSeek 的最新版本有什么特性？"              │   │
│  └─────────────────────────────────────────────────────┘   │
│                          ↓                                  │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ LLM 生成回答：                                       │   │
│  │ "DeepSeek-V3 于 2024 年 12 月发布，采用 MoE 架构，   │   │
│  │  拥有 671B 参数，支持 128K 上下文窗口..."            │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 核心知识点

#### 🔑 关键概念（必须理解）

| 概念 | 定义 | 类比理解 |
|------|------|----------|
| **参数化知识** | 模型权重中固化的知识（训练时学到的） | 你脑子里记住的东西 |
| **非参数化知识** | 外部知识库中的数据（可随时更新） | 你手边的参考书 |
| **Embedding** | 将文本转为向量表示 | 给文本"编码"成数字 |
| **向量数据库** | 存储和检索向量的数据库 | 智能图书馆 |
| **语义搜索** | 基于含义而非关键词的搜索 | 理解你想要什么，而非逐字匹配 |
| **幻觉（Hallucination）** | LLM 编造不存在的信息 | "一本正经胡说八道" |

#### 💡 核心洞见（RAG 的独特价值）

1. **知识的"内外结合"**
   - 参数化知识：模型"记住"的，模糊、可能过时
   - 非参数化知识：外部资料，精准、可实时更新
   - **类比**：既用脑子记，也查参考书

2. **开卷考试 vs 闭卷考试**
   - 纯 LLM：闭卷考试，只能靠记忆
   - RAG：开卷考试，可以查资料
   - **类比**：允许带小抄的考试，成绩自然更好

3. **可溯源 = 可信赖**
   - 每个回答都能追溯到原始文档
   - "有据可查"提高可信度
   - **类比**：论文要有参考文献

4. **知识热拔插**
   - 更新知识库，无需重新训练模型
   - 新数据入库，立刻可用
   - **类比**：换张存储卡，瞬间换知识

---

## 📚 深度讲解

### 1. 为什么需要 RAG？LLM 有什么局限？

**LLM 的四大局限**：

| 局限 | 描述 | 示例 |
|------|------|------|
| **知识截止** | 训练数据有截止日期 | "2024 年世界杯冠军是谁？"→ 不知道 |
| **幻觉问题** | 编造不存在的信息 | 虚构论文、虚构 API |
| **领域知识缺失** | 缺乏专业/私有数据 | 公司内部文档、行业规范 |
| **无法溯源** | 不知道答案从哪来 | 法律、医疗场景需要引用出处 |

**RAG 的解决方案**：

| LLM 局限 | RAG 解决方案 |
|----------|--------------|
| 知识截止 | 外部知识库可实时更新 |
| 幻觉问题 | 基于检索结果生成，有据可依 |
| 领域知识缺失 | 接入私有知识库 |
| 无法溯源 | 返回引用的原始文档 |

---

### 2. RAG vs 微调 vs 提示工程：如何选择？

**技术选型路径**：提示工程 → RAG → 微调

```
┌─────────────────────────────────────────────────────────────┐
│                    技术选型矩阵                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  LLM 优化程度 →                                             │
│  (是否修改模型)                                             │
│                                                             │
│       低                                         高         │
│       ├──────────────────────────────────────────┤         │
│       │                                          │         │
│  上   │  ┌─────────┐                             │         │
│  下   │  │   RAG   │  ← 不改模型，增强上下文     │         │
│  文   │  └─────────┘                             │         │
│  优   │                                          │         │
│  化   │  ┌─────────┐              ┌─────────┐   │         │
│  程   │  │ 提示工程 │              │  微调   │   │         │
│  度   │  └─────────┘              └─────────┘   │         │
│  ↓   │  ↑ 不改模型               ↑ 直接改模型  │         │
│       │    不增强上下文             改变行为/风格│         │
│  低   │                                          │         │
│       └──────────────────────────────────────────┘         │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**选择指南**：

| 技术 | 适用场景 | 成本 | 示例 |
|------|----------|------|------|
| **提示工程** | 任务简单，模型已有知识 | 最低 | 优化提问方式 |
| **RAG** | 需要特定/实时知识 | 中等 | 企业知识库问答 |
| **微调** | 改变模型行为/风格 | 最高 | 特定格式输出、角色扮演 |

**核心区别**：
- **RAG 解决"知道什么"**：补充模型不知道的知识
- **微调解决"如何做"**：改变模型的行为方式

---

### 3. RAG 的技术演进：从 Naive 到 Modular

**三代 RAG 架构**：

| 阶段 | 特点 | 流程 |
|------|------|------|
| **Naive RAG** | 最简单的线性流程 | 检索 → 生成 |
| **Advanced RAG** | 增加预处理和后处理 | 预处理 → 检索 → 后处理 → 生成 |
| **Modular RAG** | 模块化、可组合 | 像乐高一样自由组合 |

**Advanced RAG 流程**：

```
┌─────────────────────────────────────────────────────────────┐
│                    Advanced RAG 流程                         │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  预检索优化（Pre-Retrieval）                                │
│  ├── 查询重写：优化用户问题                                 │
│  ├── 查询扩展：生成多个相关查询                             │
│  └── 查询分解：复杂问题拆分为子问题                         │
│                          ↓                                  │
│  检索优化（Retrieval）                                      │
│  ├── 混合检索：向量 + 关键词                                │
│  ├── 多路召回：多个检索策略并行                             │
│  └── 元数据过滤：按来源、时间等筛选                         │
│                          ↓                                  │
│  后检索优化（Post-Retrieval）                               │
│  ├── 重排序（Rerank）：对结果二次排序                       │
│  ├── 压缩：去除冗余信息                                     │
│  └── 融合：合并多路结果                                     │
│                          ↓                                  │
│  生成优化（Generation）                                     │
│  ├── 自我修正：检查并修正错误                               │
│  └── 引用标注：标注答案来源                                 │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

### 4. 四步构建最小可行 RAG 系统

**Step 1：数据准备与清洗**

```python
# 加载多种格式的文档
from langchain.document_loaders import PyPDFLoader, Docx2txtLoader

# 文本分块（关键！）
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,      # 每块 500 字符
    chunk_overlap=50,    # 重叠 50 字符，保持上下文连贯
    separators=["\n\n", "\n", "。", "！", "？"]  # 按语义分割
)
chunks = splitter.split_documents(documents)
```

**分块策略的重要性**：

| 策略 | 优点 | 缺点 |
|------|------|------|
| 固定长度 | 简单 | 可能切断语义 |
| 按段落 | 保持语义完整 | 长度不均 |
| 递归分割 | 平衡语义和长度 | 需要调参 |

**Step 2：索引构建**

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma

# 向量化并存入数据库
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(
    documents=chunks,
    embedding=embeddings,
    persist_directory="./chroma_db"
)
```

**Step 3：检索策略优化**

```python
# 混合检索：向量 + 关键词
from langchain.retrievers import BM25Retriever, EnsembleRetriever

# BM25（关键词检索）
bm25_retriever = BM25Retriever.from_documents(chunks)

# 向量检索
vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# 混合检索
ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, vector_retriever],
    weights=[0.3, 0.7]  # 向量检索权重更高
)
```

**Step 4：生成与提示工程**

```python
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA

prompt_template = """
你是一个专业的问答助手。请根据以下参考资料回答问题。
如果资料中没有相关信息，请直接说"我不知道"，不要编造答案。

参考资料：
{context}

问题：{question}

回答：
"""

prompt = PromptTemplate(
    template=prompt_template,
    input_variables=["context", "question"]
)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=ensemble_retriever,
    chain_type_kwargs={"prompt": prompt}
)
```

---

### 5. RAG vs 长上下文：谁会胜出？

**对比分析**：

| 维度 | 长上下文 | RAG |
|------|----------|-----|
| **成本** | Token 数 × 单价，成本高 | 只检索相关部分，成本低 |
| **延迟** | 处理长文本慢 | 检索后只处理少量文本 |
| **准确性** | "大海捞针"问题 | 精准定位相关信息 |
| **可扩展性** | 受限于上下文窗口 | 知识库可无限扩展 |
| **可溯源** | 难以定位信息来源 | 天然支持引用标注 |

**"大海捞针"问题**：
- 长上下文中，模型对中间位置的信息关注度下降
- 关键信息如果在中间，可能被忽略
- RAG 通过检索，把关键信息放在最前面

**最佳实践：融合使用**

| 知识库规模 | 推荐方案 |
|------------|----------|
| 小规模（< 100K tokens） | 直接塞进长上下文 |
| 中等规模（100K - 1M tokens） | RAG 检索 + 长上下文融合 |
| 大规模（> 1M tokens） | 必须用 RAG |

**结论**：RAG 不会死，而是会与长上下文融合，形成更强大的架构。

---

### 6. RAG 的适用场景与风险分级

**适用场景风险分级**：

| 风险等级 | 场景 | RAG 适用性 | 注意事项 |
|----------|------|------------|----------|
| **低风险** | 内部知识问答、FAQ | ⭐⭐⭐⭐⭐ 非常适合 | 可容忍少量错误 |
| **中风险** | 客服、技术支持 | ⭐⭐⭐⭐ 适合 | 需要人工审核机制 |
| **高风险** | 医疗、法律、金融 | ⭐⭐⭐ 谨慎使用 | 必须可溯源、人工复核 |
| **极高风险** | 自动决策、合规 | ⭐⭐ 不推荐单独使用 | 需要多重验证 |

**最佳应用场景**：

| 场景 | 原因 | 示例 |
|------|------|------|
| **企业知识库** | 私有数据、实时更新 | 内部文档问答 |
| **客服系统** | 产品知识、FAQ | 智能客服机器人 |
| **研究助手** | 论文检索、文献综述 | 学术问答 |
| **代码助手** | 项目文档、API 文档 | 代码生成 |
| **合规审查** | 法规检索、政策解读 | 合规问答（需人工复核） |

---

## ✅ 行动清单

### 立即可做（今天）

- [ ] 阅读 all-in-rag 第一章：解锁 RAG（⏱️ 30分钟）
- [ ] 用 FastGPT 或 Dify 快速体验 RAG（⏱️ 15分钟）
- [ ] 思考：你的工作中有哪些场景适合用 RAG？（⏱️ 10分钟）

### 短期实践（本周）

- [ ] 搭建一个最小可行 RAG 系统（⏱️ 2小时）
- [ ] 尝试不同的分块策略，对比效果（⏱️ 1小时）
- [ ] 学习混合检索（向量 + BM25）（⏱️ 1小时）

### 长期提升（持续）

- [ ] 完成 all-in-rag 全部章节
- [ ] 学习 Advanced RAG 技术（查询重写、Rerank）
- [ ] 探索 Graph RAG（知识图谱 + RAG）

---

## 📋 一页纸总结

### 核心要点（5 条）

1. **RAG = 检索 + 生成**：让 LLM 从"闭卷考试"变成"开卷考试"
2. **解决 LLM 四大局限**：知识截止、幻觉、领域缺失、无法溯源
3. **技术选型路径**：提示工程 → RAG → 微调，优先选成本最低的
4. **四步构建 MVP**：数据准备 → 索引构建 → 检索优化 → 生成集成
5. **RAG 不会死**：会与长上下文融合，形成更强大的架构

### 金句摘录

> "RAG 就是让 LLM 学会了'开卷考试'，它既能利用自己学到的知识，也能随时查阅外部资料。"

> "RAG 的核心在于'将 LLM 的内在参数化知识与外部非参数化知识相结合'。"

> "RAG 的生命力，正在于它的'面目全非'和'包罗万象'。"

---

## 📚 延伸阅读

- [Datawhale all-in-rag](https://github.com/datawhalechina/all-in-rag)
- [RAG 原始论文](https://arxiv.org/abs/2005.11401)（Lewis et al., 2020）
- [Modular RAG 论文](https://arxiv.org/abs/2407.21059)（Gao et al., 2024）
- [TinyRAG](https://github.com/KMnO4-zx/TinyRAG)（轻量级 RAG 实现）
- [FastGPT](https://github.com/labring/FastGPT)（可视化 RAG 平台）
- [Dify](https://github.com/langgenius/dify)（LLM 应用开发平台）
